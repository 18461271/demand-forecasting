{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Demand forecasting with BigQuery and TensorFlow</h1>\n",
    "\n",
    "In this notebook, we will develop a machine learning model to predict the demand for taxi cabs in New York.\n",
    "\n",
    "To develop the model, we will need to get historical data of taxicab usage. This data exists in BigQuery. Let's start by looking at the schema."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import google.datalab.bigquery as bq\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bqsv\" id=\"1_154870394206\"></div>\n",
       "    <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "    <script>\n",
       "      require.config({\n",
       "        paths: {\n",
       "          base: '/static/base',\n",
       "        },\n",
       "        map: {\n",
       "          '*': {\n",
       "            datalab: 'nbextensions/gcpdatalab'\n",
       "          }\n",
       "        },\n",
       "      });\n",
       "\n",
       "      require(['datalab/bigquery', 'datalab/element!1_154870394206',\n",
       "          'datalab/style!/nbextensions/gcpdatalab/bigquery.css'],\n",
       "        function(bq, dom) {\n",
       "          bq.renderSchema(dom, [{\"name\": \"vendor_id\", \"type\": \"STRING\", \"description\": \"A code indicating the TPEP provider that provided the record. 1= Creative Mobile Technologies, LLC; 2= VeriFone Inc\", \"mode\": \"REQUIRED\"}, {\"name\": \"pickup_datetime\", \"type\": \"TIMESTAMP\", \"description\": \"The date and time when the meter was engaged.\", \"mode\": \"NULLABLE\"}, {\"name\": \"dropoff_datetime\", \"type\": \"TIMESTAMP\", \"description\": \"The date and time when the meter was disengaged.\", \"mode\": \"NULLABLE\"}, {\"name\": \"passenger_count\", \"type\": \"INTEGER\", \"description\": \"The number of passengers in the vehicle. This is a driver-entered value\", \"mode\": \"NULLABLE\"}, {\"name\": \"trip_distance\", \"type\": \"FLOAT\", \"description\": \"The elapsed trip distance in miles reported by the taximeter.\", \"mode\": \"NULLABLE\"}, {\"name\": \"pickup_longitude\", \"type\": \"FLOAT\", \"description\": \"Longitude where the meter was engaged.\", \"mode\": \"NULLABLE\"}, {\"name\": \"pickup_latitude\", \"type\": \"FLOAT\", \"description\": \"Latitude where the meter was engaged.\", \"mode\": \"NULLABLE\"}, {\"name\": \"rate_code\", \"type\": \"INTEGER\", \"description\": \"The final rate code in effect at the end of the trip. 1= Standard rate 2=JFK 3=Newark 4=Nassau or Westchester 5=Negotiated fare 6=Group ride\", \"mode\": \"NULLABLE\"}, {\"name\": \"store_and_fwd_flag\", \"type\": \"STRING\", \"description\": \"This flag indicates whether the trip record was held in vehicle memory before sending to the vendor, aka \\u201cstore and forward,\\u201d because the vehicle did not have a connection to the server. Y= store and forward trip N= not a store and forward trip\", \"mode\": \"NULLABLE\"}, {\"name\": \"dropoff_longitude\", \"type\": \"FLOAT\", \"description\": \"Longitude where the meter was disengaged\", \"mode\": \"NULLABLE\"}, {\"name\": \"dropoff_latitude\", \"type\": \"FLOAT\", \"description\": \"Latitude where the meter was disengaged.\", \"mode\": \"NULLABLE\"}, {\"name\": \"payment_type\", \"type\": \"STRING\", \"description\": \"A numeric code signifying how the passenger paid for the trip. 1= Credit card 2= Cash 3= No charge 4= Dispute 5= Unknown 6= Voided trip\", \"mode\": \"NULLABLE\"}, {\"name\": \"fare_amount\", \"type\": \"FLOAT\", \"description\": \"The time-and-distance fare calculated by the meter\", \"mode\": \"NULLABLE\"}, {\"name\": \"extra\", \"type\": \"FLOAT\", \"description\": \"Miscellaneous extras and surcharges. Currently, this only includes the $0.50 and $1 rush hour and overnight charges.\", \"mode\": \"NULLABLE\"}, {\"name\": \"mta_tax\", \"type\": \"FLOAT\", \"description\": \"$0.50 MTA tax that is automatically triggered based on the metered rate in use\", \"mode\": \"NULLABLE\"}, {\"name\": \"tip_amount\", \"type\": \"FLOAT\", \"description\": \"Tip amount \\u2013 This field is automatically populated for credit card tips. Cash tips are not included\", \"mode\": \"NULLABLE\"}, {\"name\": \"tolls_amount\", \"type\": \"FLOAT\", \"description\": \"Total amount of all tolls paid in trip.\", \"mode\": \"NULLABLE\"}, {\"name\": \"imp_surcharge\", \"type\": \"FLOAT\", \"description\": \"$0.30 improvement surcharge assessed trips at the flag drop. The improvement surcharge began being levied in 2015.\", \"mode\": \"NULLABLE\"}, {\"name\": \"total_amount\", \"type\": \"FLOAT\", \"description\": \"The total amount charged to passengers. Does not include cash tips\", \"mode\": \"NULLABLE\"}]);\n",
       "        }\n",
       "      );\n",
       "    </script>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%bq tables describe --name bigquery-public-data.new_york.tlc_yellow_trips_2015"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Analyzing taxicab demand </h2>\n",
    "\n",
    "Let's pull the number of trips for each day in the 2015 dataset using Standard SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bqtv\" id=\"2_154870396593\"><table><tr><th>daynumber</th></tr><tr><td>301</td></tr><tr><td>178</td></tr><tr><td>308</td></tr><tr><td>336</td></tr><tr><td>150</td></tr></table></div>\n",
       "    <br />(rows: 5, time: 1.1s,     1GB processed, job: job_2vcJtVxQ_ahkDgxr5dar4uQYjRXU)<br />\n",
       "    <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "    <script>\n",
       "      require.config({\n",
       "        paths: {\n",
       "          base: '/static/base',\n",
       "          d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.13/d3',\n",
       "          plotly: 'https://cdn.plot.ly/plotly-1.5.1.min.js?noext',\n",
       "          jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min'\n",
       "        },\n",
       "        map: {\n",
       "          '*': {\n",
       "            datalab: 'nbextensions/gcpdatalab'\n",
       "          }\n",
       "        },\n",
       "        shim: {\n",
       "          plotly: {\n",
       "            deps: ['d3', 'jquery'],\n",
       "            exports: 'plotly'\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "\n",
       "      require(['datalab/charting', 'datalab/element!2_154870396593', 'base/js/events',\n",
       "          'datalab/style!/nbextensions/gcpdatalab/charting.css'],\n",
       "        function(charts, dom, events) {\n",
       "          charts.render('gcharts', dom, events, 'table', [], {\"cols\": [{\"id\": \"daynumber\", \"type\": \"number\", \"label\": \"daynumber\"}], \"rows\": [{\"c\": [{\"v\": 301}]}, {\"c\": [{\"v\": 178}]}, {\"c\": [{\"v\": 308}]}, {\"c\": [{\"v\": 336}]}, {\"c\": [{\"v\": 150}]}]},\n",
       "            {\n",
       "              pageSize: 25,\n",
       "              cssClassNames:  {\n",
       "                tableRow: 'gchart-table-row',\n",
       "                headerRow: 'gchart-table-headerrow',\n",
       "                oddTableRow: 'gchart-table-oddrow',\n",
       "                selectedTableRow: 'gchart-table-selectedrow',\n",
       "                hoverTableRow: 'gchart-table-hoverrow',\n",
       "                tableCell: 'gchart-table-cell',\n",
       "                headerCell: 'gchart-table-headercell',\n",
       "                rowNumberCell: 'gchart-table-rownumcell'\n",
       "              }\n",
       "            },\n",
       "            {source_index: 0, fields: 'daynumber'},\n",
       "            0,\n",
       "            5);\n",
       "        }\n",
       "      );\n",
       "    </script>\n",
       "  "
      ],
      "text/plain": [
       "QueryResultsTable job_2vcJtVxQ_ahkDgxr5dar4uQYjRXU"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%bq query\n",
    "SELECT \n",
    "  EXTRACT (DAYOFYEAR from pickup_datetime) AS daynumber\n",
    "FROM `bigquery-public-data.new_york.tlc_yellow_trips_2015` \n",
    "LIMIT 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Modular queries and Pandas dataframe </h3>\n",
    "\n",
    "Let's use the total number of trips as our proxy for taxicab demand (other reasonable alternatives are total trip_distance or total fare_amount).  It is possible to predict multiple variables using Tensorflow, but for simplicity, we will stick to just predicting the number of trips.\n",
    "\n",
    "We will give our query a name 'taxiquery' and have it use an input variable '$YEAR'. We can then invoke the 'taxiquery' by giving it a YEAR.  The to_dataframe() converts the BigQuery result into a <a href='http://pandas.pydata.org/'>Pandas</a> dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bq query -n taxiquery\n",
    "WITH trips AS (\n",
    "  SELECT EXTRACT (DAYOFYEAR from pickup_datetime) AS daynumber \n",
    "  FROM `bigquery-public-data.new_york.tlc_yellow_trips_*`\n",
    "  where _TABLE_SUFFIX = @YEAR\n",
    ")\n",
    "SELECT daynumber, COUNT(1) AS numtrips FROM trips\n",
    "GROUP BY daynumber ORDER BY daynumber"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>daynumber</th>\n",
       "      <th>numtrips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>382014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>345296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>406769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>328848</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>363454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>384324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>429653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>450920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>447947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>515540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>419629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>396367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>448517</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>442656</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>451186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>478124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>476827</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>427042</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>342795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>405581</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    daynumber  numtrips\n",
       "0           1    382014\n",
       "1           2    345296\n",
       "2           3    406769\n",
       "3           4    328848\n",
       "4           5    363454\n",
       "5           6    384324\n",
       "6           7    429653\n",
       "7           8    450920\n",
       "8           9    447947\n",
       "9          10    515540\n",
       "10         11    419629\n",
       "11         12    396367\n",
       "12         13    448517\n",
       "13         14    442656\n",
       "14         15    451186\n",
       "15         16    478124\n",
       "16         17    476827\n",
       "17         18    427042\n",
       "18         19    342795\n",
       "19         20    405581"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query_parameters = [\n",
    "  {\n",
    "    'name': 'YEAR',\n",
    "    'parameterType': {'type': 'STRING'},\n",
    "    'parameterValue': {'value': 2015}\n",
    "  }\n",
    "]\n",
    "trips = taxiquery.execute(query_params=query_parameters).result().to_dataframe()\n",
    "trips[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Benchmark </h3>\n",
    "\n",
    "Often, a reasonable estimate of something is its historical average. We can therefore benchmark our machine learning model against the historical average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Just using average=400309.5589041096 has RMSE of 51613.65169049127\n"
     ]
    }
   ],
   "source": [
    "avg = np.mean(trips['numtrips'])\n",
    "print('Just using average={0} has RMSE of {1}'.format(avg, np.sqrt(np.mean((trips['numtrips'] - avg)**2))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The mean here is about 400,000 and the root-mean-square-error (RMSE) in this case is about 52,000. In other words, if we were to estimate that there are 400,000 taxi trips on any given day, that estimate is will be off on average by about 52,000 in either direction.\n",
    "  \n",
    "Let's see if we can do better than this -- our goal is to make predictions of taxicab demand whose RMSE is lower than 52,000.\n",
    "\n",
    "What kinds of things affect people's use of taxicabs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Weather data </h2>\n",
    "\n",
    "We suspect that weather influences how often people use a taxi. Perhaps someone who'd normally walk to work would take a taxi if it is very cold or rainy.\n",
    "\n",
    "One of the advantages of using a global data warehouse like BigQuery is that you get to mash up unrelated datasets quite easily."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div class=\"bqtv\" id=\"3_154870429670\"><table><tr><th>usaf</th><th>wban</th><th>name</th><th>country</th><th>state</th><th>call</th><th>lat</th><th>lon</th><th>elev</th><th>begin</th><th>end</th></tr><tr><td>725030</td><td>14732</td><td>LA GUARDIA AIRPORT</td><td>US</td><td>NY</td><td>KLGA</td><td>40.779</td><td>-73.88</td><td>+0003.4</td><td>19730101</td><td>20190127</td></tr></table></div>\n",
       "    <br />(rows: 1, time: 0.7s,     2MB processed, job: job_KK7NxG7W_9Lk8BLqumv0I61MB8bY)<br />\n",
       "    <script src=\"/static/components/requirejs/require.js\"></script>\n",
       "    <script>\n",
       "      require.config({\n",
       "        paths: {\n",
       "          base: '/static/base',\n",
       "          d3: '//cdnjs.cloudflare.com/ajax/libs/d3/3.4.13/d3',\n",
       "          plotly: 'https://cdn.plot.ly/plotly-1.5.1.min.js?noext',\n",
       "          jquery: '//ajax.googleapis.com/ajax/libs/jquery/2.0.0/jquery.min'\n",
       "        },\n",
       "        map: {\n",
       "          '*': {\n",
       "            datalab: 'nbextensions/gcpdatalab'\n",
       "          }\n",
       "        },\n",
       "        shim: {\n",
       "          plotly: {\n",
       "            deps: ['d3', 'jquery'],\n",
       "            exports: 'plotly'\n",
       "          }\n",
       "        }\n",
       "      });\n",
       "\n",
       "      require(['datalab/charting', 'datalab/element!3_154870429670', 'base/js/events',\n",
       "          'datalab/style!/nbextensions/gcpdatalab/charting.css'],\n",
       "        function(charts, dom, events) {\n",
       "          charts.render('gcharts', dom, events, 'table', [], {\"cols\": [{\"id\": \"usaf\", \"type\": \"string\", \"label\": \"usaf\"}, {\"id\": \"wban\", \"type\": \"string\", \"label\": \"wban\"}, {\"id\": \"name\", \"type\": \"string\", \"label\": \"name\"}, {\"id\": \"country\", \"type\": \"string\", \"label\": \"country\"}, {\"id\": \"state\", \"type\": \"string\", \"label\": \"state\"}, {\"id\": \"call\", \"type\": \"string\", \"label\": \"call\"}, {\"id\": \"lat\", \"type\": \"number\", \"label\": \"lat\"}, {\"id\": \"lon\", \"type\": \"number\", \"label\": \"lon\"}, {\"id\": \"elev\", \"type\": \"string\", \"label\": \"elev\"}, {\"id\": \"begin\", \"type\": \"string\", \"label\": \"begin\"}, {\"id\": \"end\", \"type\": \"string\", \"label\": \"end\"}], \"rows\": [{\"c\": [{\"v\": \"725030\"}, {\"v\": \"14732\"}, {\"v\": \"LA GUARDIA AIRPORT\"}, {\"v\": \"US\"}, {\"v\": \"NY\"}, {\"v\": \"KLGA\"}, {\"v\": 40.779}, {\"v\": -73.88}, {\"v\": \"+0003.4\"}, {\"v\": \"19730101\"}, {\"v\": \"20190127\"}]}]},\n",
       "            {\n",
       "              pageSize: 25,\n",
       "              cssClassNames:  {\n",
       "                tableRow: 'gchart-table-row',\n",
       "                headerRow: 'gchart-table-headerrow',\n",
       "                oddTableRow: 'gchart-table-oddrow',\n",
       "                selectedTableRow: 'gchart-table-selectedrow',\n",
       "                hoverTableRow: 'gchart-table-hoverrow',\n",
       "                tableCell: 'gchart-table-cell',\n",
       "                headerCell: 'gchart-table-headercell',\n",
       "                rowNumberCell: 'gchart-table-rownumcell'\n",
       "              }\n",
       "            },\n",
       "            {source_index: 1, fields: 'usaf,wban,name,country,state,call,lat,lon,elev,begin,end'},\n",
       "            0,\n",
       "            1);\n",
       "        }\n",
       "      );\n",
       "    </script>\n",
       "  "
      ],
      "text/plain": [
       "QueryResultsTable job_KK7NxG7W_9Lk8BLqumv0I61MB8bY"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%bq query\n",
    "SELECT * FROM `bigquery-public-data.noaa_gsod.stations`\n",
    "WHERE state = 'NY' AND wban != '99999' AND name LIKE '%LA GUARDIA%'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Variables </h3>\n",
    "\n",
    "Let's pull out the minimum and maximum daily temperature (in Fahrenheit) as well as the amount of rain (in inches) for La Guardia airport."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%bq query -n wxquery\n",
    "SELECT EXTRACT (DAYOFYEAR FROM CAST(CONCAT(@YEAR,'-',mo,'-',da) AS TIMESTAMP)) AS daynumber,\n",
    "       MIN(EXTRACT (DAYOFWEEK FROM CAST(CONCAT(@YEAR,'-',mo,'-',da) AS TIMESTAMP))) dayofweek,\n",
    "       MIN(min) mintemp, MAX(max) maxtemp, MAX(IF(prcp=99.99,0,prcp)) rain\n",
    "FROM `bigquery-public-data.noaa_gsod.gsod*`\n",
    "WHERE stn='725030' AND _TABLE_SUFFIX = @YEAR\n",
    "GROUP BY 1 ORDER BY daynumber DESC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_parameters = [\n",
    "  {\n",
    "    'name': 'YEAR',\n",
    "    'parameterType': {'type': 'STRING'},\n",
    "    'parameterValue': {'value': 2015}\n",
    "  }\n",
    "]\n",
    "weather = wxquery.execute(query_params=query_parameters).result().to_dataframe()\n",
    "weather[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Merge datasets </h3>\n",
    "\n",
    "Let's use Pandas to merge (combine) the taxi cab and weather datasets day-by-day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.merge(weather, trips, on='daynumber')\n",
    "data[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Exploratory analysis </h3>\n",
    "\n",
    "Is there a relationship between maximum temperature and the number of trips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = data.plot(kind='scatter', x='maxtemp', y='numtrips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The scatterplot above doesn't look very promising. There appears to be a weak downward trend, but it's also quite noisy.\n",
    "\n",
    "Is there a relationship between the day of the week and the number of trips?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = data.plot(kind='scatter', x='dayofweek', y='numtrips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hurrah, we seem to have found a predictor. It appears that people use taxis more later in the week. Perhaps New Yorkers make weekly resolutions to walk more and then lose their determination later in the week, or maybe it reflects tourism dynamics in New York City.\n",
    "\n",
    "Perhaps if we took out the <em>confounding</em> effect of the day of the week, maximum temperature will start to have an effect. Let's see if that's the case:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = data[data['dayofweek'] == 7].plot(kind='scatter', x='maxtemp', y='numtrips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Removing the confounding factor does seem to reflect an underlying trend around temperature. But ... the data are a little sparse, don't you think?  This is something that you have to keep in mind -- the more predictors you start to consider (here we are using two: day of week and maximum temperature), the more rows you will need so as to avoid <em> overfitting </em> the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Adding 2014 and 2016 data </h3>\n",
    "\n",
    "Let's add in 2014 and 2016 data to the Pandas dataframe.  Note how useful it was for us to modularize our queries around the YEAR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = data # 2015 data\n",
    "for year in [2014, 2016]:\n",
    "    query_parameters = [\n",
    "      {\n",
    "        'name': 'YEAR',\n",
    "        'parameterType': {'type': 'STRING'},\n",
    "        'parameterValue': {'value': year}\n",
    "      }\n",
    "    ]\n",
    "    weather = wxquery.execute(query_params=query_parameters).result().to_dataframe()\n",
    "    trips = taxiquery.execute(query_params=query_parameters).result().to_dataframe()\n",
    "    data_for_year = pd.merge(weather, trips, on='daynumber')\n",
    "    data2 = pd.concat([data2, data_for_year])\n",
    "data2.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "j = data2[data2['dayofweek'] == 7].plot(kind='scatter', x='maxtemp', y='numtrips')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data do seem a bit more robust.  If we had even more data, it would be better of course. But in this case, we only have 2014-2016 data for taxi trips, so that's what we will go with."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Machine Learning with Tensorflow </h2>\n",
    "\n",
    "We'll use 80% of our dataset for training and 20% of the data for testing the model we have trained. Let's shuffle the rows of the Pandas dataframe so that this division is random.  The predictor (or input) columns will be every column in the database other than the number-of-trips (which is our target, or what we want to predict).\n",
    "\n",
    "The machine learning models that we will use -- linear regression and neural networks -- both require that the input variables are numeric in nature.\n",
    "\n",
    "The day of the week, however, is a categorical variable (i.e. Tuesday is not really greater than Monday). So, we should create separate columns for whether it is a Monday (with values 0 or 1), Tuesday, etc.\n",
    "\n",
    "Against that, we do have limited data (remember: the more columns you use as input features, the more rows you need to have in your training dataset), and it appears that there is a clear linear trend by day of the week. So, we will opt for simplicity here and use the data as-is.  Try uncommenting the code that creates separate columns for the days of the week and re-run the notebook if you are curious about the impact of this simplification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "shuffled = data2.sample(frac=1, random_state=13)\n",
    "# It would be a good idea, if we had more data, to treat the days as categorical variables\n",
    "# with the small amount of data, we have though, the model tends to overfit\n",
    "#predictors = shuffled.iloc[:,2:5]\n",
    "#for day in range(1,8):\n",
    "#  matching = shuffled['dayofweek'] == day\n",
    "#  key = 'day_' + str(day)\n",
    "#  predictors[key] = pd.Series(matching, index=predictors.index, dtype=float)\n",
    "predictors = shuffled.iloc[:,1:5]\n",
    "predictors[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = shuffled.iloc[:,5]\n",
    "targets[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's update our benchmark based on the 80-20 split and the larger dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainsize = int(len(shuffled['numtrips']) * 0.8)\n",
    "avg = np.mean(shuffled['numtrips'][:trainsize])\n",
    "rmse = np.sqrt(np.mean((targets[trainsize:] - avg)**2))\n",
    "print('Just using average={0} has RMSE of {1}'.format(avg, rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Linear regression with tf.contrib.learn </h2>\n",
    "\n",
    "We scale the number of taxicab rides by 400,000 so that the model can keep its predicted values in the [0-1] range. The optimization goes a lot faster when the weights are small numbers.  We save the weights into ./trained_model_linear and display the root mean square error on the test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_NUM_TRIPS = 600000.0\n",
    "trainsize = int(len(shuffled['numtrips']) * 0.8)\n",
    "testsize = len(shuffled['numtrips']) - trainsize\n",
    "npredictors = len(predictors.columns)\n",
    "noutputs = 1\n",
    "tf.logging.set_verbosity(tf.logging.WARN) # change to INFO to get output every 100 steps ...\n",
    "shutil.rmtree('./trained_model_linear', ignore_errors=True) # so that we don't load weights from previous runs\n",
    "estimator = tf.contrib.learn.LinearRegressor(model_dir='./trained_model_linear',\n",
    "                                             feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values))\n",
    "\n",
    "print(\"starting to train ... this will take a while ... use verbosity=INFO to get more verbose output\")\n",
    "def input_fn(features, targets):\n",
    "  return tf.constant(features.values), tf.constant(targets.values.reshape(len(targets), noutputs)/SCALE_NUM_TRIPS)\n",
    "estimator.fit(input_fn=lambda: input_fn(predictors[:trainsize], targets[:trainsize]), steps=10000)\n",
    "\n",
    "pred = np.multiply(list(estimator.predict(predictors[trainsize:].values)), SCALE_NUM_TRIPS )\n",
    "rmse = np.sqrt(np.mean(np.power((targets[trainsize:].values - pred), 2)))\n",
    "print('LinearRegression has RMSE of {0}'.format(rmse))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The RMSE here (57K) is lower than the benchmark (62K) indicates that we are doing about 10% better with the machine learning model than we would be if we were to just use the historical average (our benchmark)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Neural network with tf.contrib.learn </h2>\n",
    "\n",
    "Let's make a more complex model with a few hidden nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_NUM_TRIPS = 600000.0\n",
    "trainsize = int(len(shuffled['numtrips']) * 0.8)\n",
    "testsize = len(shuffled['numtrips']) - trainsize\n",
    "npredictors = len(predictors.columns)\n",
    "noutputs = 1\n",
    "tf.logging.set_verbosity(tf.logging.WARN) # change to INFO to get output every 100 steps ...\n",
    "shutil.rmtree('./trained_model', ignore_errors=True) # so that we don't load weights from previous runs\n",
    "estimator = tf.contrib.learn.DNNRegressor(model_dir='./trained_model',\n",
    "                                          hidden_units=[5, 5],                             \n",
    "                                          feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(predictors.values))\n",
    "\n",
    "print(\"starting to train ... this will take a while ... use verbosity=INFO to get more verbose output\")\n",
    "def input_fn(features, targets):\n",
    "  return tf.constant(features.values), tf.constant(targets.values.reshape(len(targets), noutputs)/SCALE_NUM_TRIPS)\n",
    "estimator.fit(input_fn=lambda: input_fn(predictors[:trainsize], targets[:trainsize]), steps=10000)\n",
    "\n",
    "pred = np.multiply(list(estimator.predict(predictors[trainsize:].values)), SCALE_NUM_TRIPS )\n",
    "rmse = np.sqrt(np.mean((targets[trainsize:].values - pred)**2))\n",
    "print('Neural Network Regression has RMSE of {0}'.format(rmse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using a neural network results in similar performance to the linear model when I ran it -- it might be because there isn't enough data for the NN to do much better. (NN training is a non-convex optimization, and you will get different results each time you run the above code)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> Running a trained model </h2>\n",
    "\n",
    "So, we have trained a model, and saved it to a file. Let's use this model to predict taxicab demand given the expected weather for three days.\n",
    "\n",
    "Here we make a Dataframe out of those inputs, load up the saved model (note that we have to know the model equation -- it's not saved in the model file) and use it to predict the taxicab demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input = pd.DataFrame.from_dict(data = \n",
    "                               {'dayofweek' : [4, 5, 6],\n",
    "                                'mintemp' : [60, 40, 50],\n",
    "                                'maxtemp' : [70, 90, 60],\n",
    "                                'rain' : [0, 0.5, 0]})\n",
    "# read trained model from ./trained_model\n",
    "estimator = tf.contrib.learn.LinearRegressor(model_dir='./trained_model_linear',\n",
    "                                          feature_columns=tf.contrib.learn.infer_real_valued_columns_from_input(input.values))\n",
    "\n",
    "pred = np.multiply(list(estimator.predict(input.values)), SCALE_NUM_TRIPS )\n",
    "print(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we should tell some of our taxi drivers to take the day off on Thursday (day=5). No wonder -- the forecast calls for extreme weather fluctuations on Thursday."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright 2017 Google Inc. Licensed under the Apache License, Version 2.0 (the \"License\"); you may not use this file except in compliance with the License. You may obtain a copy of the License at http://www.apache.org/licenses/LICENSE-2.0 Unless required by applicable law or agreed to in writing, software distributed under the License is distributed on an \"AS IS\" BASIS, WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the License for the specific language governing permissions and limitations under the License"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
